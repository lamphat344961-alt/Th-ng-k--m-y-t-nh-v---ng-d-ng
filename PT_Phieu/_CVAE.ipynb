{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5a4070c",
   "metadata": {},
   "source": [
    "# CVAE - Conditional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f31757d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3a3cd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 44\n",
      "\n",
      "Saved outputs to: C:\\Users\\Admin\\Desktop\\TANPHAT\\hocotruong\\Năm ba 2025-2026\\HK1_B\\Thống kê máy tính và ứng dụng\\PT_Phieu\\cvae_discrete_outputs\n",
      "Train class counts:\n",
      " p1q9_job_current\n",
      "0    318\n",
      "1    113\n",
      "2     74\n",
      "3     89\n",
      "4     11\n",
      "5      2\n",
      "Name: count, dtype: int64\n",
      "Test  class counts:\n",
      " p1q9_job_current\n",
      "0    80\n",
      "1    28\n",
      "2    18\n",
      "3    22\n",
      "4     3\n",
      "5     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Synthesis plan:\n",
      "    class  current_train_count  target_train_count  need_raw  need_capped  \\\n",
      "0      4                   11                  74        63           63   \n",
      "1      5                    2                  74        72           72   \n",
      "\n",
      "   cap_factor  min_real_to_generate  forced_generate_anyway  \\\n",
      "0          40                     8                    True   \n",
      "1          40                     8                    True   \n",
      "\n",
      "   warning_too_few_real  \n",
      "0                 False  \n",
      "1                  True  \n",
      "\n",
      "Files:\n",
      " - C:\\Users\\Admin\\Desktop\\TANPHAT\\hocotruong\\Năm ba 2025-2026\\HK1_B\\Thống kê máy tính và ứng dụng\\PT_Phieu\\cvae_discrete_outputs\\cvae_discrete.pt\n",
      " - C:\\Users\\Admin\\Desktop\\TANPHAT\\hocotruong\\Năm ba 2025-2026\\HK1_B\\Thống kê máy tính và ứng dụng\\PT_Phieu\\cvae_discrete_outputs\\synth_plan.csv\n",
      " - C:\\Users\\Admin\\Desktop\\TANPHAT\\hocotruong\\Năm ba 2025-2026\\HK1_B\\Thống kê máy tính và ứng dụng\\PT_Phieu\\cvae_discrete_outputs\\real_vs_synthetic_for_bar.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======================\n",
    "# CONFIG\n",
    "# ======================\n",
    "DATA_PATH = \"dataset_THCS_only_filtered.csv\"\n",
    "OUT_DIR = Path(\"cvae_discrete_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TARGET = \"p1q9_job_current\"\n",
    "N_CLASSES = 6\n",
    "\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Train CVAE\n",
    "EPOCHS = 250\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-3\n",
    "LATENT = 32\n",
    "HIDDEN = 256\n",
    "\n",
    "BETA = 1.0\n",
    "WARMUP_EPOCHS = 50\n",
    "EARLY_STOP_PATIENCE = 25\n",
    "\n",
    "# Hold-out\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Synthetic target:\n",
    "# Default: bring class 4&5 up to min(count of classes 0..3) within TRAIN\n",
    "SYN_CLASSES = [4, 5]\n",
    "\n",
    "# IMPORTANT SAFETY CAPS (highly recommended for your data)\n",
    "# - cap_factor: don't generate more than cap_factor * real_count for a class\n",
    "# - min_real_to_generate: if class has < this many real samples, generation is extremely risky\n",
    "CAP_FACTOR = 40           # e.g. at most 4x the real count\n",
    "MIN_REAL_TO_GENERATE = 8  # class < 8 => warn (still generate if you insist)\n",
    "FORCE_GENERATE_ANYWAY = True  # set False to skip too-small classes automatically\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Reproducibility\n",
    "# ======================\n",
    "def set_seed(seed: int = 42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Column grouping (purely value-based)\n",
    "# - Any negative values -> categorical\n",
    "# - Binary {0,1}\n",
    "# - Likert subset of {1..5}\n",
    "# - Small integer code (<=20 unique) -> categorical\n",
    "# ======================\n",
    "@dataclass\n",
    "class ColumnGroups:\n",
    "    binary: List[str]\n",
    "    likert: List[str]\n",
    "    categorical: List[str]\n",
    "    other_numeric: List[str]\n",
    "\n",
    "\n",
    "def infer_column_groups(df: pd.DataFrame, feature_cols: List[str]) -> ColumnGroups:\n",
    "    binary, likert, categorical, other_numeric = [], [], [], []\n",
    "\n",
    "    for c in feature_cols:\n",
    "        s = df[c].dropna()\n",
    "        if len(s) == 0:\n",
    "            categorical.append(c)\n",
    "            continue\n",
    "\n",
    "        if (s < 0).any():\n",
    "            categorical.append(c)\n",
    "            continue\n",
    "\n",
    "        uniq = np.sort(s.unique())\n",
    "\n",
    "        if len(uniq) <= 2 and set(uniq).issubset({0, 1}):\n",
    "            binary.append(c)\n",
    "            continue\n",
    "\n",
    "        if set(uniq).issubset({1, 2, 3, 4, 5}):\n",
    "            likert.append(c)\n",
    "            continue\n",
    "\n",
    "        # small integer code -> categorical\n",
    "        is_int_like = pd.api.types.is_integer_dtype(s) or np.all(np.equal(np.mod(uniq, 1), 0))\n",
    "        if is_int_like and len(uniq) <= 20:\n",
    "            categorical.append(c)\n",
    "            continue\n",
    "\n",
    "        other_numeric.append(c)\n",
    "\n",
    "    return ColumnGroups(binary=binary, likert=likert, categorical=categorical, other_numeric=other_numeric)\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Categorical encoder (per-column index mapping)\n",
    "# ======================\n",
    "@dataclass\n",
    "class CatEncoder:\n",
    "    cols: List[str]\n",
    "    categories_: Dict[str, np.ndarray]\n",
    "    to_index_: Dict[str, Dict[float, int]]\n",
    "    to_value_: Dict[str, Dict[int, float]]\n",
    "\n",
    "    @staticmethod\n",
    "    def fit(df: pd.DataFrame, cols: List[str]) -> \"CatEncoder\":\n",
    "        categories_ = {}\n",
    "        to_index_ = {}\n",
    "        to_value_ = {}\n",
    "\n",
    "        for c in cols:\n",
    "            cats = np.sort(df[c].dropna().unique())\n",
    "            categories_[c] = cats\n",
    "            to_index_[c] = {float(v): i for i, v in enumerate(cats)}\n",
    "            to_value_[c] = {i: float(v) for i, v in enumerate(cats)}\n",
    "\n",
    "        return CatEncoder(cols, categories_, to_index_, to_value_)\n",
    "\n",
    "    def transform(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        out = np.zeros((len(df), len(self.cols)), dtype=np.int64)\n",
    "        for j, c in enumerate(self.cols):\n",
    "            m = self.to_index_[c]\n",
    "            out[:, j] = df[c].map(lambda x: m.get(float(x), 0)).to_numpy(dtype=np.int64)\n",
    "        return out\n",
    "\n",
    "    def inverse_transform(self, X_idx: np.ndarray) -> pd.DataFrame:\n",
    "        data = {}\n",
    "        for j, c in enumerate(self.cols):\n",
    "            inv = self.to_value_[c]\n",
    "            data[c] = np.vectorize(lambda i: inv.get(int(i), inv[0]))(X_idx[:, j])\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# ======================\n",
    "# PreparedData\n",
    "# ======================\n",
    "@dataclass\n",
    "class PreparedData:\n",
    "    groups: ColumnGroups\n",
    "    cat_enc: CatEncoder\n",
    "    binary_cols: List[str]\n",
    "    likert_cols: List[str]\n",
    "    cat_cols: List[str]\n",
    "    cat_sizes: List[int]\n",
    "\n",
    "\n",
    "def prepare(df_train: pd.DataFrame, feature_cols: List[str]) -> PreparedData:\n",
    "    groups = infer_column_groups(df_train, feature_cols)\n",
    "    cat_enc = CatEncoder.fit(df_train, groups.categorical)\n",
    "    cat_sizes = [len(cat_enc.categories_[c]) for c in groups.categorical]\n",
    "\n",
    "    return PreparedData(\n",
    "        groups=groups,\n",
    "        cat_enc=cat_enc,\n",
    "        binary_cols=groups.binary,\n",
    "        likert_cols=groups.likert,\n",
    "        cat_cols=groups.categorical,\n",
    "        cat_sizes=cat_sizes\n",
    "    )\n",
    "\n",
    "\n",
    "def to_model_inputs(df: pd.DataFrame, prep: PreparedData) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    # binary float32 0/1\n",
    "    Xb = df[prep.binary_cols].to_numpy(dtype=np.float32) if prep.binary_cols else np.zeros((len(df), 0), np.float32)\n",
    "\n",
    "    # likert indices 0..4\n",
    "    if prep.likert_cols:\n",
    "        Xl = df[prep.likert_cols].to_numpy(dtype=np.int64) - 1\n",
    "        Xl = np.clip(Xl, 0, 4)\n",
    "    else:\n",
    "        Xl = np.zeros((len(df), 0), dtype=np.int64)\n",
    "\n",
    "    # categorical indices per col 0..K-1\n",
    "    Xc = prep.cat_enc.transform(df) if prep.cat_cols else np.zeros((len(df), 0), dtype=np.int64)\n",
    "\n",
    "    return Xb, Xl, Xc\n",
    "\n",
    "\n",
    "def onehot_y(y: np.ndarray, n_classes: int) -> np.ndarray:\n",
    "    oh = np.zeros((len(y), n_classes), dtype=np.float32)\n",
    "    oh[np.arange(len(y)), y.astype(int)] = 1.0\n",
    "    return oh\n",
    "\n",
    "\n",
    "# ======================\n",
    "# CVAE Mixed-type (Discrete)\n",
    "# Condition y via concatenation in BOTH encoder and decoder\n",
    "# Encoder input = [x_onehot_expanded, y_onehot]\n",
    "# Decoder input = [z, y_onehot]\n",
    "# ======================\n",
    "class CVAE_Discrete(nn.Module):\n",
    "    def __init__(self, n_bin: int, n_likert: int, cat_sizes: List[int], y_dim: int):\n",
    "        super().__init__()\n",
    "        self.n_bin = n_bin\n",
    "        self.n_likert = n_likert\n",
    "        self.cat_sizes = cat_sizes\n",
    "        self.y_dim = y_dim\n",
    "\n",
    "        # expanded x for encoder:\n",
    "        # binary float n_bin\n",
    "        # likert one-hot 5 each => n_likert*5\n",
    "        # categorical one-hot sum(cat_sizes)\n",
    "        x_enc_dim = n_bin + n_likert * 5 + int(np.sum(cat_sizes))\n",
    "        enc_in = x_enc_dim + y_dim\n",
    "\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Linear(enc_in, HIDDEN),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN, HIDDEN),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.mu = nn.Linear(HIDDEN, LATENT)\n",
    "        self.logvar = nn.Linear(HIDDEN, LATENT)\n",
    "\n",
    "        self.dec_trunk = nn.Sequential(\n",
    "            nn.Linear(LATENT + y_dim, HIDDEN),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN, HIDDEN),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # heads\n",
    "        self.bin_head = nn.Linear(HIDDEN, n_bin) if n_bin > 0 else None\n",
    "        self.likert_head = nn.Linear(HIDDEN, n_likert * 5) if n_likert > 0 else None\n",
    "        self.cat_heads = nn.ModuleList([nn.Linear(HIDDEN, k) for k in cat_sizes])\n",
    "\n",
    "    def _encode_x(self, xb: torch.Tensor, xl: torch.Tensor, xc: torch.Tensor) -> torch.Tensor:\n",
    "        parts = []\n",
    "        if self.n_bin > 0:\n",
    "            parts.append(xb)\n",
    "\n",
    "        if self.n_likert > 0:\n",
    "            xl_oh = F.one_hot(xl, num_classes=5).float()  # [B, n_likert, 5]\n",
    "            parts.append(xl_oh.view(xl_oh.size(0), -1))\n",
    "\n",
    "        if len(self.cat_sizes) > 0:\n",
    "            oh_list = []\n",
    "            for j, k in enumerate(self.cat_sizes):\n",
    "                oh_list.append(F.one_hot(xc[:, j], num_classes=k).float())\n",
    "            parts.append(torch.cat(oh_list, dim=1))\n",
    "\n",
    "        return torch.cat(parts, dim=1) if parts else torch.zeros((xb.size(0), 0), device=xb.device)\n",
    "\n",
    "    def forward(self, xb: torch.Tensor, xl: torch.Tensor, xc: torch.Tensor, y_oh: torch.Tensor):\n",
    "        x_in = self._encode_x(xb, xl, xc)\n",
    "        h = self.enc(torch.cat([x_in, y_oh], dim=1))\n",
    "        mu = self.mu(h)\n",
    "        logvar = self.logvar(h)\n",
    "\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        z = mu + std * torch.randn_like(std)\n",
    "\n",
    "        hd = self.dec_trunk(torch.cat([z, y_oh], dim=1))\n",
    "\n",
    "        bin_logits = self.bin_head(hd) if self.bin_head is not None else None\n",
    "        likert_logits = self.likert_head(hd).view(-1, self.n_likert, 5) if self.likert_head is not None else None\n",
    "        cat_logits = [head(hd) for head in self.cat_heads]  # list [B,k]\n",
    "\n",
    "        return bin_logits, likert_logits, cat_logits, mu, logvar\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, n: int, class_id: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        z = torch.randn((n, LATENT), device=DEVICE)\n",
    "        y = torch.zeros((n, self.y_dim), device=DEVICE)\n",
    "        y[:, class_id] = 1.0\n",
    "\n",
    "        hd = self.dec_trunk(torch.cat([z, y], dim=1))\n",
    "\n",
    "        # binary\n",
    "        if self.bin_head is not None:\n",
    "            p = torch.sigmoid(self.bin_head(hd))\n",
    "            xb = torch.bernoulli(p).cpu().numpy().astype(np.int64)\n",
    "        else:\n",
    "            xb = np.zeros((n, 0), dtype=np.int64)\n",
    "\n",
    "        # likert\n",
    "        if self.likert_head is not None:\n",
    "            logits = self.likert_head(hd).view(n, self.n_likert, 5)\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            xl = torch.multinomial(probs.view(-1, 5), 1).view(n, self.n_likert).cpu().numpy().astype(np.int64)\n",
    "        else:\n",
    "            xl = np.zeros((n, 0), dtype=np.int64)\n",
    "\n",
    "        # categorical\n",
    "        xc_list = []\n",
    "        for head in self.cat_heads:\n",
    "            probs = torch.softmax(head(hd), dim=-1)\n",
    "            idx = torch.multinomial(probs, 1).squeeze(1)\n",
    "            xc_list.append(idx.cpu().numpy().astype(np.int64))\n",
    "        xc = np.stack(xc_list, axis=1) if xc_list else np.zeros((n, 0), dtype=np.int64)\n",
    "\n",
    "        return xb, xl, xc\n",
    "\n",
    "def cvae_loss_improved(\n",
    "    bin_logits, likert_logits, cat_logits,\n",
    "    xb, xl, xc,\n",
    "    mu, logvar,\n",
    "    beta: float,\n",
    "    n_bin: int,\n",
    "    n_likert: int,\n",
    "    n_cat: int,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:  # ✅ Trả về tuple\n",
    "    \"\"\"\n",
    "    Reconstruction loss normalized by number of features per type\n",
    "    Returns: (total_loss, recon_loss, kl_loss)\n",
    "    \"\"\"\n",
    "\n",
    "    recon = 0.0\n",
    "    total_feats = 0\n",
    "\n",
    "    # Binary\n",
    "    if bin_logits is not None and xb.numel() > 0 and n_bin > 0:\n",
    "        recon_bin = F.binary_cross_entropy_with_logits(\n",
    "            bin_logits, xb, reduction=\"mean\"\n",
    "        )\n",
    "        recon = recon + recon_bin * n_bin\n",
    "        total_feats += n_bin\n",
    "\n",
    "    # Likert\n",
    "    if likert_logits is not None and xl.numel() > 0 and n_likert > 0:\n",
    "        recon_lik = F.cross_entropy(\n",
    "            likert_logits.view(-1, 5),\n",
    "            xl.view(-1),\n",
    "            reduction=\"mean\"\n",
    "        )\n",
    "        recon = recon + recon_lik * n_likert\n",
    "        total_feats += n_likert\n",
    "\n",
    "    # Categorical\n",
    "    if cat_logits and xc.numel() > 0 and n_cat > 0:\n",
    "        ce_list = []\n",
    "        for j, logits in enumerate(cat_logits):\n",
    "            ce_list.append(\n",
    "                F.cross_entropy(logits, xc[:, j], reduction=\"mean\")\n",
    "            )\n",
    "        recon_cat = torch.stack(ce_list).mean()\n",
    "        recon = recon + recon_cat * n_cat\n",
    "        total_feats += n_cat\n",
    "\n",
    "    # Normalize\n",
    "    if total_feats > 0:\n",
    "        recon = recon / total_feats\n",
    "\n",
    "    # KL divergence\n",
    "    kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    total_loss = recon + beta * kl\n",
    "    return total_loss, recon, kl  # ✅\n",
    "\n",
    "\n",
    "def train_cvae(\n",
    "    Xb: np.ndarray, Xl: np.ndarray, Xc: np.ndarray, y: np.ndarray,\n",
    "    prep: PreparedData\n",
    ") -> CVAE_Discrete:\n",
    "    \n",
    "    idx = np.arange(len(y))\n",
    "    idx_tr, idx_va = train_test_split(idx, test_size=0.15, random_state=SEED, stratify=y)\n",
    "\n",
    "    def make_loader(ix, shuffle: bool):\n",
    "        xb = torch.tensor(Xb[ix], dtype=torch.float32)\n",
    "        xl = torch.tensor(Xl[ix], dtype=torch.long)\n",
    "        xc = torch.tensor(Xc[ix], dtype=torch.long)\n",
    "        y_oh = torch.tensor(onehot_y(y[ix], N_CLASSES), dtype=torch.float32)\n",
    "        ds = TensorDataset(xb, xl, xc, y_oh)\n",
    "        return DataLoader(ds, batch_size=BATCH_SIZE, shuffle=shuffle, drop_last=False)\n",
    "\n",
    "    dl_tr = make_loader(idx_tr, True)\n",
    "    dl_va = make_loader(idx_va, False)\n",
    "\n",
    "    model = CVAE_Discrete(\n",
    "        n_bin=Xb.shape[1],\n",
    "        n_likert=Xl.shape[1],\n",
    "        cat_sizes=prep.cat_sizes,\n",
    "        y_dim=N_CLASSES\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    patience = 0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        beta = BETA * min(1.0, epoch / float(WARMUP_EPOCHS))\n",
    "\n",
    "        # ========== TRAINING ==========\n",
    "        model.train()\n",
    "        for xb, xl, xc, y_oh in dl_tr:\n",
    "            xb, xl, xc, y_oh = xb.to(DEVICE), xl.to(DEVICE), xc.to(DEVICE), y_oh.to(DEVICE)\n",
    "\n",
    "            bin_logits, likert_logits, cat_logits, mu, logvar = model(xb, xl, xc, y_oh)\n",
    "            \n",
    "            loss, _, _ = cvae_loss_improved(  # ✅ Unpack tuple\n",
    "                bin_logits, likert_logits, cat_logits,\n",
    "                xb, xl, xc,\n",
    "                mu, logvar,\n",
    "                beta=beta,\n",
    "                n_bin=len(prep.binary_cols),\n",
    "                n_likert=len(prep.likert_cols),\n",
    "                n_cat=len(prep.cat_cols),\n",
    "            )\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        # ========== VALIDATION ==========\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for xb, xl, xc, y_oh in dl_va:\n",
    "                xb, xl, xc, y_oh = xb.to(DEVICE), xl.to(DEVICE), xc.to(DEVICE), y_oh.to(DEVICE)\n",
    "                bin_logits, likert_logits, cat_logits, mu, logvar = model(xb, xl, xc, y_oh)\n",
    "                \n",
    "                val_loss, _, _ = cvae_loss_improved(  # ✅ Unpack tuple\n",
    "                    bin_logits, likert_logits, cat_logits,\n",
    "                    xb, xl, xc,\n",
    "                    mu, logvar,\n",
    "                    beta=beta,\n",
    "                    n_bin=len(prep.binary_cols),\n",
    "                    n_likert=len(prep.likert_cols),\n",
    "                    n_cat=len(prep.cat_cols),\n",
    "                )\n",
    "                val_losses.append(val_loss.item())  # ✅ THÊM .item()\n",
    "\n",
    "        val_loss = float(np.mean(val_losses))\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss + 1e-6 < best_val:\n",
    "            best_val = val_loss\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= EARLY_STOP_PATIENCE:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Export helpers for bar comparison\n",
    "# ======================\n",
    "def make_bar_df_from_samples(\n",
    "    prep: PreparedData,\n",
    "    xb_s: np.ndarray, xl_s: np.ndarray, xc_s: np.ndarray,\n",
    "    cls: int\n",
    ") -> pd.DataFrame:\n",
    "    data = {}\n",
    "\n",
    "    # binary\n",
    "    for j, c in enumerate(prep.binary_cols):\n",
    "        data[c] = xb_s[:, j].astype(int)\n",
    "\n",
    "    # likert back to 1..5\n",
    "    for j, c in enumerate(prep.likert_cols):\n",
    "        data[c] = (xl_s[:, j] + 1).astype(int)\n",
    "\n",
    "    # categorical back to original codes\n",
    "    if prep.cat_cols:\n",
    "        df_cat = prep.cat_enc.inverse_transform(xc_s)\n",
    "        for c in prep.cat_cols:\n",
    "            data[c] = df_cat[c].values\n",
    "\n",
    "    df_out = pd.DataFrame(data)\n",
    "    df_out[TARGET] = cls\n",
    "    df_out[\"source\"] = \"synthetic\"\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def main():\n",
    "    set_seed(SEED)\n",
    "\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    if TARGET not in df.columns:\n",
    "        raise ValueError(f\"Missing target '{TARGET}' in {DATA_PATH}\")\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c != TARGET]\n",
    "\n",
    "    # Hold-out split (stratified)\n",
    "    df_tr, df_te = train_test_split(df, test_size=TEST_SIZE, random_state=SEED, stratify=df[TARGET])\n",
    "    df_tr = df_tr.reset_index(drop=True)\n",
    "    df_te = df_te.reset_index(drop=True)\n",
    "\n",
    "    # Fit preprocessing on TRAIN only\n",
    "    prep = prepare(df_tr, feature_cols)\n",
    "\n",
    "    # Prepare model inputs on TRAIN (all classes)\n",
    "    Xb_tr, Xl_tr, Xc_tr = to_model_inputs(df_tr, prep)\n",
    "    y_tr = df_tr[TARGET].astype(int).to_numpy()\n",
    "\n",
    "    # Train 1 CVAE on TRAIN\n",
    "    cvae = train_cvae(Xb_tr, Xl_tr, Xc_tr, y_tr, prep)\n",
    "    torch.save(cvae.state_dict(), OUT_DIR / \"cvae_discrete.pt\")\n",
    "\n",
    "    # Compute target count (min among 0..3)\n",
    "    counts = df_tr[TARGET].value_counts().to_dict()\n",
    "    target_n = min(counts.get(k, 0) for k in [0, 1, 2, 3])\n",
    "\n",
    "    plan_rows = []\n",
    "    synthetic_frames = []\n",
    "\n",
    "    # Save REAL train subset for bar comparison\n",
    "    keep_cols = prep.binary_cols + prep.likert_cols + prep.cat_cols\n",
    "    df_real_bar = df_tr[keep_cols].copy()\n",
    "    df_real_bar[TARGET] = df_tr[TARGET].astype(int)\n",
    "    df_real_bar[\"source\"] = \"real\"\n",
    "    df_real_bar.to_csv(OUT_DIR / \"real_train_for_bar.csv\", index=False)\n",
    "\n",
    "    for cls in SYN_CLASSES:\n",
    "        cur = int(counts.get(cls, 0))\n",
    "        need = max(0, target_n - cur)\n",
    "\n",
    "        # caps to avoid extreme oversampling (strongly recommended)\n",
    "        cap = int(max(0, CAP_FACTOR * cur))\n",
    "        if cap > 0:\n",
    "            need_capped = min(need, cap)\n",
    "        else:\n",
    "            need_capped = need\n",
    "\n",
    "        too_small = cur < MIN_REAL_TO_GENERATE\n",
    "        if too_small and not FORCE_GENERATE_ANYWAY:\n",
    "            need_capped = 0\n",
    "\n",
    "        plan_rows.append({\n",
    "            \"class\": cls,\n",
    "            \"current_train_count\": cur,\n",
    "            \"target_train_count\": int(target_n),\n",
    "            \"need_raw\": int(need),\n",
    "            \"need_capped\": int(need_capped),\n",
    "            \"cap_factor\": CAP_FACTOR,\n",
    "            \"min_real_to_generate\": MIN_REAL_TO_GENERATE,\n",
    "            \"forced_generate_anyway\": FORCE_GENERATE_ANYWAY,\n",
    "            \"warning_too_few_real\": bool(too_small),\n",
    "        })\n",
    "\n",
    "        if need_capped <= 0:\n",
    "            continue\n",
    "\n",
    "        # Sample synthetic with condition class_id\n",
    "        xb_s, xl_s, xc_s = cvae.sample(n=need_capped, class_id=cls)\n",
    "\n",
    "        df_syn_bar = make_bar_df_from_samples(prep, xb_s, xl_s, xc_s, cls)\n",
    "        synthetic_frames.append(df_syn_bar)\n",
    "\n",
    "    pd.DataFrame(plan_rows).to_csv(OUT_DIR / \"synth_plan.csv\", index=False)\n",
    "\n",
    "    if synthetic_frames:\n",
    "        df_syn_all = pd.concat(synthetic_frames, ignore_index=True)\n",
    "        df_syn_all.to_csv(OUT_DIR / \"synthetic_for_bar.csv\", index=False)\n",
    "        df_bar = pd.concat([df_real_bar, df_syn_all], ignore_index=True)\n",
    "    else:\n",
    "        df_bar = df_real_bar.copy()\n",
    "\n",
    "    df_bar.to_csv(OUT_DIR / \"real_vs_synthetic_for_bar.csv\", index=False)\n",
    "\n",
    "    print(\"\\nSaved outputs to:\", OUT_DIR.resolve())\n",
    "    print(\"Train class counts:\\n\", df_tr[TARGET].value_counts().sort_index())\n",
    "    print(\"Test  class counts:\\n\", df_te[TARGET].value_counts().sort_index())\n",
    "    print(\"\\nSynthesis plan:\\n\", pd.DataFrame(plan_rows))\n",
    "    print(\"\\nFiles:\")\n",
    "    print(\" -\", (OUT_DIR / \"cvae_discrete.pt\").resolve())\n",
    "    print(\" -\", (OUT_DIR / \"synth_plan.csv\").resolve())\n",
    "    print(\" -\", (OUT_DIR / \"real_vs_synthetic_for_bar.csv\").resolve())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370dcf2",
   "metadata": {},
   "source": [
    "# Trực quan kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad101fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(r\"cvae_discrete_outputs\\real_vs_synthetic_for_bar.csv\")\n",
    "\n",
    "sns.countplot(\n",
    "    data=df,\n",
    "    x=\"p1q9_job_current\",\n",
    "    hue=\"source\"\n",
    ")\n",
    "\n",
    "plt.title(\"So sánh số lượng mẫu theo nhóm ngành (Real vs Synthetic)\")\n",
    "plt.xlabel(\"Nhóm ngành\")\n",
    "plt.ylabel(\"Số lượng\")\n",
    "plt.legend(title=\"Nguồn dữ liệu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7f1cc9",
   "metadata": {},
   "source": [
    "# 🔄 Chiến Lược Kiểm Định: Stratified K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b70851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# CONFIG\n",
    "# ======================\n",
    "DATA_PATH = r\"cvae_discrete_outputs\\synthetic_for_bar.csv\"\n",
    "OUT_DIR = Path(\"cvae_cv_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TARGET = \"p1q9_job_current\"\n",
    "N_SPLITS = 3\n",
    "SEED = 42\n",
    "\n",
    "# ======================\n",
    "# LOAD DATA\n",
    "# ======================\n",
    "df1 = pd.read_csv(DATA_PATH)\n",
    "df1.drop(columns=['source'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd4e36af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(r\"dataset_THCS_only_filtered.csv\")\n",
    "\n",
    "df = pd.concat(\n",
    "    [df1, df2],\n",
    "    ignore_index=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97c74014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "- Total samples: 894\n",
      "- Folds: 3\n",
      "- Full class distribution:\n",
      "   class  count\n",
      "0      0    398\n",
      "1      1    141\n",
      "3      2     92\n",
      "2      3    111\n",
      "4      4     77\n",
      "5      5     75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET]\n",
    "\n",
    "# ======================\n",
    "# FULL CLASS DISTRIBUTION\n",
    "# ======================\n",
    "class_counts_full = (\n",
    "    y.value_counts()\n",
    "     .rename_axis(\"class\")\n",
    "     .reset_index(name=\"count\")\n",
    "     .sort_values(\"class\")\n",
    ")\n",
    "# Lưu lại số lượng từng lớp\n",
    "class_counts_full.to_csv(\n",
    "    OUT_DIR / \"class_counts_full.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "\n",
    "# ======================\n",
    "# STRATIFIED K-FOLD (3 folds)\n",
    "# ======================\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=N_SPLITS,\n",
    "    shuffle=True,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "fold_indices = []\n",
    "per_fold_counts = []\n",
    "\n",
    "for fold_id, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    fold_indices.append({\n",
    "        \"fold\": fold_id,\n",
    "        \"train_idx\": train_idx,\n",
    "        \"val_idx\": val_idx,\n",
    "    })\n",
    "\n",
    "    # class distribution in validation fold\n",
    "    fold_counts = (\n",
    "        y.iloc[val_idx]\n",
    "        .value_counts()\n",
    "        .rename_axis(\"class\")\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "    fold_counts[\"fold\"] = fold_id\n",
    "    per_fold_counts.append(fold_counts)\n",
    "\n",
    "# ======================\n",
    "# SAVE FOLDS\n",
    "# ======================\n",
    "with open(OUT_DIR / \"cvae_cv_folds.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fold_indices, f)\n",
    "\n",
    "class_counts_per_fold = (\n",
    "    pd.concat(per_fold_counts, ignore_index=True)\n",
    "      .sort_values([\"fold\", \"class\"])\n",
    ")\n",
    "\n",
    "class_counts_per_fold.to_csv(\n",
    "    OUT_DIR / \"class_counts_per_fold.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"DONE\")\n",
    "print(f\"- Total samples: {len(df)}\")\n",
    "print(f\"- Folds: {N_SPLITS}\")\n",
    "print(\"- Full class distribution:\")\n",
    "print(class_counts_full)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc71261e",
   "metadata": {},
   "source": [
    "# Training voi RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "03a5e380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (894, 183)\n",
      "Class distribution:\n",
      " p1q9_job_current\n",
      "0    398\n",
      "1    141\n",
      "2     92\n",
      "3    111\n",
      "4     77\n",
      "5     75\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# DATA_PATH = \"cvae_discrete_outputs/real_vs_synthetic_for_bar.csv\"\n",
    "FOLDS_PATH = \"cvae_cv_outputs/cvae_cv_folds.pkl\"\n",
    "# TARGET = \"p1q9_job_current\"\n",
    "\n",
    "# Load data\n",
    "# df = pd.read_csv(DATA_PATH)\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET].astype(int)\n",
    "\n",
    "# Load CV folds (đã chuẩn bị sẵn)\n",
    "with open(FOLDS_PATH, \"rb\") as f:\n",
    "    folds = pickle.load(f)\n",
    "\n",
    "print(\"Data shape:\", X.shape)\n",
    "print(\"Class distribution:\\n\", y.value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0c7927c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[RF_CVAE] FOLD 0\n",
      "balanced_accuracy: 0.3892\n",
      "f1_macro:         0.3662\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7606    0.8120    0.7855       133\n",
      "           1     0.4444    0.7660    0.5625        47\n",
      "           2     0.4231    0.3667    0.3929        30\n",
      "           3     0.2439    0.2703    0.2564        37\n",
      "           4     0.0000    0.0000    0.0000        26\n",
      "           5     0.6000    0.1200    0.2000        25\n",
      "\n",
      "    accuracy                         0.5638       298\n",
      "   macro avg     0.4120    0.3892    0.3662       298\n",
      "weighted avg     0.5328    0.5638    0.5274       298\n",
      "\n",
      "confusion_matrix:\n",
      "[[108   6   6  13   0   0]\n",
      " [  3  36   2   6   0   0]\n",
      " [  7   4  11   8   0   0]\n",
      " [  2  20   4  10   1   0]\n",
      " [ 10  10   2   2   0   2]\n",
      " [ 12   5   1   2   2   3]]\n",
      "\n",
      "================================================================================\n",
      "[RF_CVAE] FOLD 1\n",
      "balanced_accuracy: 0.4219\n",
      "f1_macro:         0.4077\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7447    0.7955    0.7692       132\n",
      "           1     0.4545    0.7447    0.5645        47\n",
      "           2     0.3750    0.4839    0.4225        31\n",
      "           3     0.3226    0.2703    0.2941        37\n",
      "           4     0.6667    0.0769    0.1379        26\n",
      "           5     0.6667    0.1600    0.2581        25\n",
      "\n",
      "    accuracy                         0.5738       298\n",
      "   macro avg     0.5384    0.4219    0.4077       298\n",
      "weighted avg     0.5947    0.5738    0.5439       298\n",
      "\n",
      "confusion_matrix:\n",
      "[[105   8   9  10   0   0]\n",
      " [  4  35   5   3   0   0]\n",
      " [ 10   2  15   4   0   0]\n",
      " [  4  16   7  10   0   0]\n",
      " [  8   7   4   3   2   2]\n",
      " [ 10   9   0   1   1   4]]\n",
      "\n",
      "================================================================================\n",
      "[RF_CVAE] FOLD 2\n",
      "balanced_accuracy: 0.4019\n",
      "f1_macro:         0.4015\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7113    0.7594    0.7345       133\n",
      "           1     0.5294    0.7660    0.6261        47\n",
      "           2     0.2564    0.3226    0.2857        31\n",
      "           3     0.2368    0.2432    0.2400        37\n",
      "           4     0.8333    0.2000    0.3226        25\n",
      "           5     0.6000    0.1200    0.2000        25\n",
      "\n",
      "    accuracy                         0.5503       298\n",
      "   macro avg     0.5279    0.4019    0.4015       298\n",
      "weighted avg     0.5773    0.5503    0.5299       298\n",
      "\n",
      "confusion_matrix:\n",
      "[[101   7  15  10   0   0]\n",
      " [  2  36   2   7   0   0]\n",
      " [ 11   3  10   6   1   0]\n",
      " [  6  13   9   9   0   0]\n",
      " [  7   6   2   3   5   2]\n",
      " [ 15   3   1   3   0   3]]\n",
      "\n",
      "################################################################################\n",
      "[RF_CVAE] MEAN RESULTS\n",
      "balanced_accuracy = 0.40429466676892906\n",
      "f1_macro          = 0.39180803299255346\n"
     ]
    }
   ],
   "source": [
    "rf_base_params = dict(\n",
    "    n_estimators=800,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=6,\n",
    "    max_features=\"sqrt\",\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "def run_cv_rf(rf_params, tag=\"\"):\n",
    "    fold_results = []\n",
    "\n",
    "    for fold in folds:\n",
    "        tr_idx = fold[\"train_idx\"]\n",
    "        va_idx = fold[\"val_idx\"]\n",
    "\n",
    "        X_tr, y_tr = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "        X_va, y_va = X.iloc[va_idx], y.iloc[va_idx]\n",
    "\n",
    "        model = RandomForestClassifier(**rf_params)\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        pred = model.predict(X_va)\n",
    "\n",
    "        bal_acc = balanced_accuracy_score(y_va, pred)\n",
    "        f1_mac = f1_score(y_va, pred, average=\"macro\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"[{tag}] FOLD {fold['fold']}\")\n",
    "        print(f\"balanced_accuracy: {bal_acc:.4f}\")\n",
    "        print(f\"f1_macro:         {f1_mac:.4f}\")\n",
    "        print(\"classification_report:\")\n",
    "        print(classification_report(y_va, pred, digits=4))\n",
    "        print(\"confusion_matrix:\")\n",
    "        print(confusion_matrix(y_va, pred))\n",
    "\n",
    "        fold_results.append((bal_acc, f1_mac))\n",
    "\n",
    "    print(\"\\n\" + \"#\" * 80)\n",
    "    print(f\"[{tag}] MEAN RESULTS\")\n",
    "    print(\"balanced_accuracy =\", np.mean([r[0] for r in fold_results]))\n",
    "    print(\"f1_macro          =\", np.mean([r[1] for r in fold_results]))\n",
    "\n",
    "\n",
    "# === RUN BASELINE ===\n",
    "run_cv_rf(rf_base_params, tag=\"RF_CVAE\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
